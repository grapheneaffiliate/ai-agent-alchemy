#!/usr/bin/env python3

"""
Verification script for structured logging implementation across the ReAct loop, browser tooling, and enhanced news pipeline.
"""

import asyncio
import logging
import sys
import os

REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, REPO_ROOT)
sys.path.insert(0, os.path.join(REPO_ROOT, 'src'))

# Add the src directory to the path

from agent.react_loop import ToolMetrics, execute_react_loop
from plugins.browser import BrowserPlugin
from plugins.enhanced_news import get_enhanced_news
from agent.react_responses import (
    format_health_analysis_response,
    format_comprehensive_analysis_response,
    format_enhancement_plan_response,
    format_intelligence_analysis_response,
)

# Configure logging to capture structured logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('structured_logging_test.log')
    ]
)

logger = logging.getLogger(__name__)

async def test_tool_metrics():
    """Test ToolMetrics functionality."""
    print("üß™ Testing ToolMetrics...")

    metrics = ToolMetrics()

    # Simulate tool usage
    metrics.record_tool_use("browser.navigate", 1.2, True)
    metrics.record_tool_use("browser.navigate", 0.8, True)
    metrics.record_tool_use("leann.analyze", 5.1, False)
    metrics.record_tool_use("news.get_enhanced_news", 2.3, True)

    summary = metrics.get_metrics_summary()
    print(f"‚úÖ ToolMetrics working: {summary['total_tool_calls']} tools used")
    return True

async def test_browser_operation_spans():
    """Test browser plugin operation spans."""
    print("üß™ Testing browser operation spans...")

    try:
        browser = BrowserPlugin(headless=True)

        # Test operation span with a simple operation
        async with browser._operation_span('test_operation', test_param="test_value") as span:
            span['status'] = 'success'
            span['result'] = 'test_result'

        print("‚úÖ Browser operation spans working")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Browser operation spans test failed: {e}")
        return False

async def test_enhanced_news_logging():
    """Test enhanced news logging functionality."""
    print("üß™ Testing enhanced news logging...")

    try:
        # Test that the enhanced news aggregator can be initialized
        # (without actually fetching news to avoid network dependencies)
        from plugins.enhanced_news_components import NewsAggregator, DynamicSourceDiscovery, ContentIntelligence

        aggregator = NewsAggregator()
        content_intel = ContentIntelligence()

        # Test content intelligence functions
        test_text = "This is a test article about artificial intelligence and machine learning technologies."
        key_points = content_intel.extract_key_points(test_text)
        entities = content_intel.extract_entities(test_text)
        sentiment = content_intel.assess_sentiment(test_text)

        print(f"‚úÖ Enhanced news components working: {len(key_points)} key points, {len(entities)} entities, sentiment: {sentiment}")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Enhanced news logging test failed: {e}")
        return False

async def test_react_responses():
    """Test react response formatters."""
    print("üß™ Testing react response formatters...")

    try:
        # Test data
        test_analysis_data = {
            'health_report': {
                'overall_health_score': 85.5,
                'health_status': 'good',
                'dimension_scores': {
                    'code_quality': 88.0,
                    'test_coverage': 82.0,
                    'documentation': 85.0
                },
                'strengths': ['Good test coverage', 'Well documented'],
                'critical_issues': [],
                'recommendations': ['Consider adding more integration tests']
            },
            'project_overview': {
                'total_files': 150,
                'python_files': 120,
                'test_files': 25,
                'main_directories': ['src', 'tests', 'docs']
            },
            'code_quality': {
                'complexity_score': 75.0,
                'total_functions': 450,
                'avg_functions_per_file': 3.75
            }
        }

        # Test all formatters
        health_response = format_health_analysis_response(test_analysis_data)
        comprehensive_response = format_comprehensive_analysis_response(test_analysis_data)
        enhancement_response = format_enhancement_plan_response(test_analysis_data)
        intelligence_response = format_intelligence_analysis_response(test_analysis_data)

        print(f"‚úÖ Response formatters working: health({len(health_response)} chars), comprehensive({len(comprehensive_response)} chars)")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è React responses test failed: {e}")
        return False

async def main():
    """Run all verification tests."""
    print("üöÄ Starting structured logging verification...")
    print("=" * 60)

    tests = [
        ("Tool Metrics", test_tool_metrics),
        ("Browser Operation Spans", test_browser_operation_spans),
        ("Enhanced News Logging", test_enhanced_news_logging),
        ("React Response Formatters", test_react_responses),
    ]

    results = []
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = await test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"‚ùå {test_name} failed with exception: {e}")
            results.append((test_name, False))

    print("\n" + "=" * 60)
    print("üìä VERIFICATION RESULTS")
    print("=" * 60)

    all_passed = True
    for test_name, passed in results:
        status = "‚úÖ PASSED" if passed else "‚ùå FAILED"
        print(f"{test_name:25} {status}")
        if not passed:
            all_passed = False

    print("\n" + "=" * 60)
    if all_passed:
        print("üéâ ALL TESTS PASSED! Structured logging implementation is working correctly.")
        print("üìã Summary of implemented features:")
        print("   ‚úÖ src/agent/react_loop.py: Logger configured, tool metrics, levelled logging")
        print("   ‚úÖ src/agent/react_responses.py: Response formatters with reusable helpers")
        print("   ‚úÖ src/plugins/browser.py: _operation_span for async operations")
        print("   ‚úÖ src/plugins/enhanced_news_components.py: Scoped logging for news operations")
        print("   ‚úÖ src/plugins/enhanced_news.py: Thin orchestrator with logging")
    else:
        print("‚ö†Ô∏è SOME TESTS FAILED! Please review the implementation.")
        return 1

    return 0

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
